{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed4f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym \n",
    "from DDPG import DDPG\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317df6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip as qt\n",
    "from qutip import tensor, basis, projection, identity, mesolve\n",
    "\n",
    "\n",
    "class STIRAP:\n",
    "    def __init__(self, N_timesteps, step_duration, step_resolution):\n",
    "        self.N_timesteps=N_timesteps\n",
    "        self.resolution=step_resolution\n",
    "        self.duration=step_duration\n",
    "        self.Omega=1\n",
    "        self.delta2_0=50\n",
    "        self.deltaP_0=50\n",
    "        self.times = np.linspace(0,N_timesteps*step_duration,N_timesteps*step_resolution)\n",
    "        self.T=self.times[-1]\n",
    "        self.full_state_his = []\n",
    "        \n",
    "    def build_hamiltonian(self, deltaP, delta2):\n",
    "        H = (deltaP*qt.projection(3,1,1) + delta2*qt.projection(3,2,2) + \n",
    "             0.5*self.Omega*(projection(3,0,1) + projection(3,1,2)\n",
    "                        + projection(3,2,1) + projection(3,1,0))\n",
    "            )\n",
    "        return H\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state=basis(3,0)\n",
    "        self.done=False\n",
    "        return self.state.full().flatten()\n",
    "    \n",
    "    def step(self, actions, alpha=1, beta=0.5):\n",
    "        inner_times = np.linspace(0,self.duration, self.resolution)\n",
    "        deltaP=actions[0]*self.deltaP_0\n",
    "        delta2=actions[1]*self.deltaP_0\n",
    "        H = self.build_hamiltonian(deltaP, delta2)\n",
    "        res = mesolve(H=H, tlist=inner_times, rho0=self.state)\n",
    "        self.full_state_his.extend(res.states[:])\n",
    "        final_state = res.states[-1]\n",
    "        self.state=final_state\n",
    "        reward = alpha*np.abs(final_state.full().flatten()[2])**2 \n",
    "#         - beta*np.abs(final_state.full().flatten()[1])**2\n",
    "        if reward>0.99:\n",
    "            self.done=True\n",
    "        else:\n",
    "            pass\n",
    "        info={}\n",
    "        return final_state.full().flatten(), reward, self.done, info\n",
    "   \n",
    "    def close(self):\n",
    "        return\n",
    "    def render(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c343960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, Best Return: 3.0921881689972186\n",
      "episode: 0, Return: 3.0921881689972186\n",
      "episode: 3, Best Return: 6.471324951040243\n",
      "episode: 25, Return: 0.025547640006487304\n",
      "episode: 50, Return: 0.07854903175552824\n",
      "episode: 75, Return: 2.629944296481004e-08\n",
      "episode: 100, Return: 1.9735022258051838e-08\n",
      "episode: 125, Return: 1.9609681661748552e-08\n",
      "episode: 150, Return: 2.1084569653672165e-08\n",
      "episode: 175, Return: 2.9388509363896165e-08\n",
      "episode: 200, Return: 2.1564084919009354e-08\n",
      "episode: 225, Return: 2.430692719182074e-08\n",
      "episode: 250, Return: 2.23100787252512e-08\n",
      "episode: 275, Return: 2.710010842639585e-08\n",
      "episode: 300, Return: 2.045287323734289e-08\n",
      "episode: 325, Return: 2.2589585408040397e-08\n",
      "episode: 350, Return: 2.658465778990319e-08\n",
      "episode: 375, Return: 2.4616512696716692e-08\n",
      "episode: 400, Return: 2.5340537739304706e-08\n",
      "episode: 425, Return: 2.1430508236815275e-08\n",
      "episode: 450, Return: 1.9436344888274538e-08\n",
      "episode: 475, Return: 2.0679625155743733e-08\n",
      "episode: 500, Return: 1.790460966011377e-08\n",
      "episode: 525, Return: 2.0931681455426768e-08\n",
      "episode: 550, Return: 2.152285389708384e-08\n",
      "episode: 575, Return: 1.838271429699787e-08\n",
      "episode: 600, Return: 2.0979544239081472e-08\n",
      "episode: 625, Return: 3.037012678085386e-08\n",
      "episode: 650, Return: 2.5642908378070864e-08\n",
      "episode: 675, Return: 2.5067749641800748e-08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8t/mf9ym9cd7rg3wmcx5k_v_5mh0000gp/T/ipykernel_31699/3012497063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnoisy_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_noisy_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_actor_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnoisy_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mepisode_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8t/mf9ym9cd7rg3wmcx5k_v_5mh0000gp/T/ipykernel_31699/283342978.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions, alpha, beta)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdelta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeltaP_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_hamiltonian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltaP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmesolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_state_his\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfinal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MADDPG/lib/python3.7/site-packages/qutip/mesolve.py\u001b[0m in \u001b[0;36mmesolve\u001b[0;34m(H, rho0, tlist, c_ops, e_ops, args, options, progress_bar, _safe_mode)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_mesolve\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         return sesolve(H, rho0, tlist, e_ops=e_ops, args=args, options=options,\n\u001b[0;32m--> 246\u001b[0;31m                        progress_bar=progress_bar, _safe_mode=_safe_mode)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MADDPG/lib/python3.7/site-packages/qutip/sesolve.py\u001b[0m in \u001b[0;36msesolve\u001b[0;34m(H, psi0, tlist, e_ops, args, options, progress_bar, _safe_mode)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     res = _generic_ode_solve(func, ode_args, psi0, tlist, e_ops, options,\n\u001b[0;32m--> 164\u001b[0;31m                              progress_bar, dims=psi0.dims)\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me_ops_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         res.expect = {e: res.expect[n]\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MADDPG/lib/python3.7/site-packages/qutip/sesolve.py\u001b[0m in \u001b[0;36m_generic_ode_solve\u001b[0;34m(func, ode_args, psi0, tlist, e_ops, opt, progress_bar, dims)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_tsteps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MADDPG/lib/python3.7/site-packages/scipy/integrate/_ode.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t, step, relax)\u001b[0m\n\u001b[1;32m    433\u001b[0m             self._y, self.t = mth(self.f, self.jac or (lambda: None),\n\u001b[1;32m    434\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                                   self.f_params, self.jac_params)\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;31m# f2py issue with tuple returns, see ticket 1187.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MADDPG/lib/python3.7/site-packages/scipy/integrate/_ode.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, f, jac, y0, t0, t1, f_params, jac_params)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         args = ((f, jac, y0, t0, t1) + tuple(self.call_args) +\n\u001b[1;32m   1008\u001b[0m                 (f_params, jac_params))\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mistate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mistate\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = STIRAP(N_timesteps=20, step_resolution=10, step_duration=4)\n",
    "acts = 2\n",
    "state_size = 3\n",
    "\n",
    "\n",
    "\n",
    "ddpg = DDPG(n_actions=acts, state_size=state_size, learning_batch_size=32, \n",
    "            act_struct=[32,32], crit_struct=[32,32])\n",
    "\n",
    "num_episodes =10000\n",
    "returns_array = np.zeros(num_episodes)\n",
    "counter = 0\n",
    "episode_length=env.N_timesteps\n",
    "training_start=1000#batch_size*5\n",
    "returns_benchmark = 0\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done=False\n",
    "    returns=0.\n",
    "    sigma = ddpg.sigma_scheduler(episode=episode, num_episodes=num_episodes)\n",
    "    t=0\n",
    "    while not done:\n",
    "        counter+=1\n",
    "        main_actor_prediction = ddpg.main_actor(state.reshape((1,state_size)))\n",
    "        noisy_predict = ddpg.get_noisy_output(main_actor_prediction, sig=sigma)\n",
    "        action = 2*noisy_predict\n",
    "        next_state, reward, done, _ = env.step(action.numpy())\n",
    "        t+=1\n",
    "        if t==episode_length:\n",
    "            done=True\n",
    "        returns+=reward\n",
    "        ddpg.store_sample(state, action, next_state, reward, done)\n",
    "        state=next_state\n",
    "\n",
    "        if counter > training_start:\n",
    "            states, actions, rewards, next_states, dones = ddpg.sample_experiences()\n",
    "            ddpg.train_critic(states=states, rewards=rewards, next_states=next_states, dones=dones)\n",
    "            ddpg.train_actor(states=states)\n",
    "            ddpg.soft_update(tau=0.05)\n",
    "    returns_array[episode] = returns\n",
    "    if returns > returns_benchmark:\n",
    "        best_actor = ddpg.main_actor\n",
    "#         best_actor.save(\"DDPG-Actor-v1-Best\".format(episode), include_optimizer=False)\n",
    "        returns_benchmark = returns\n",
    "        print(\"episode: {}, Best Return: {}\".format(episode,returns))\n",
    "    if episode%25==0:\n",
    "#         main_actor.save(\"DDPG-Actor-v0-episode-{}\".format(episode), include_optimizer=False)\n",
    "        print(\"episode: {}, Return: {}\".format(episode,returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions=np.zeros((2,env.N_timesteps))\n",
    "state = env.reset()\n",
    "done=False\n",
    "returns=0.\n",
    "sigma = ddpg.sigma_scheduler(episode=episode, num_episodes=num_episodes)\n",
    "t=0\n",
    "while not done:\n",
    "    counter+=1\n",
    "    main_actor_prediction = best_actor(state.reshape((1,state_size)))\n",
    "    noisy_predict = ddpg.get_noisy_output(main_actor_prediction, sig=0)\n",
    "    action = noisy_predict\n",
    "    next_state, reward, done, _ = env.step(action.numpy())\n",
    "    actions[:,t]=action.numpy()[:]\n",
    "    t+=1\n",
    "    if t==episode_length:\n",
    "        done=True\n",
    "    state=next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ccfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(np.arange(env.N_timesteps), actions[0])\n",
    "plt.step(np.arange(env.N_timesteps), actions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = np.zeros((3,env.times.shape[0]))\n",
    "for i, t in enumerate(env.times):\n",
    "    populations[:,i]=np.abs(env.full_state_his[i].full().flatten()[:])**2\n",
    "    \n",
    "plt.plot(env.times, populations[0,:], label=\"|0>\")\n",
    "plt.plot(env.times, populations[1,:], label=\"|1>\")\n",
    "plt.plot(env.times, populations[2,:], label=\"|2>\")\n",
    "plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b11cc67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 0.84042394, -1.        ], dtype=float32)>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13832420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
